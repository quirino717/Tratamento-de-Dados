{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1yDFeB0kF8Xb8TQ5SXp3C_SAXnCluuWu5","timestamp":1746752977728}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fYQIwv2Hm5DU","executionInfo":{"status":"ok","timestamp":1746751047180,"user_tz":180,"elapsed":18084,"user":{"displayName":"Leonardo Quirino","userId":"09188993055052121239"}},"outputId":"bbc0dc7b-88d4-44ab-c37d-9b71366824ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Avaliação Sem Balanceamento:\n","              precision    recall  f1-score   support\n","\n","           0       0.89      0.93      0.91      7455\n","           1       0.74      0.63      0.68      2314\n","\n","    accuracy                           0.86      9769\n","   macro avg       0.81      0.78      0.79      9769\n","weighted avg       0.85      0.86      0.85      9769\n","\n","\n","Avaliação com SMOTE (Over-sampling):\n","              precision    recall  f1-score   support\n","\n","           0       0.90      0.89      0.90      7455\n","           1       0.67      0.68      0.67      2314\n","\n","    accuracy                           0.84      9769\n","   macro avg       0.78      0.79      0.79      9769\n","weighted avg       0.84      0.84      0.84      9769\n","\n","\n","Avaliação com Random Under-sampling:\n","              precision    recall  f1-score   support\n","\n","           0       0.94      0.80      0.86      7455\n","           1       0.56      0.84      0.67      2314\n","\n","    accuracy                           0.81      9769\n","   macro avg       0.75      0.82      0.77      9769\n","weighted avg       0.85      0.81      0.82      9769\n","\n","\n","Avaliação com Balanceamento por Custo:\n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.93      0.91      7455\n","           1       0.74      0.61      0.67      2314\n","\n","    accuracy                           0.86      9769\n","   macro avg       0.81      0.77      0.79      9769\n","weighted avg       0.85      0.86      0.85      9769\n","\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.datasets import load_wine\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report\n","from imblearn.over_sampling import SMOTE\n","from imblearn.under_sampling import RandomUnderSampler\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Carregar o dataset Adult Income\n","url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n","columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n","\n","# Carregar os dados com pandas\n","data = pd.read_csv(url, names=columns, sep=',\\s', engine='python')\n","\n","# Pré-processamento\n","# Substituir valores ausentes\n","data.replace(\" ?\", np.nan, inplace=True)\n","data.dropna(inplace=True)\n","\n","# Convertendo variáveis categóricas para numéricas\n","label_encoders = {}\n","for column in data.select_dtypes(include=['object']).columns:\n","    le = LabelEncoder()\n","    data[column] = le.fit_transform(data[column])\n","    label_encoders[column] = le\n","\n","# Definir características e rótulos\n","X = data.drop(columns='income')\n","y = data['income']\n","\n","# Dividir em treino e teste\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Inicializar o classificador\n","rf = RandomForestClassifier(random_state=42)\n","\n","# Técnicas de balanceamento\n","smote = SMOTE(random_state=42)\n","rus = RandomUnderSampler(random_state=42)\n","\n","# Balanceamento por Custo (pesos das classes ajustados)\n","rf_cost = RandomForestClassifier(random_state=42, class_weight='balanced')\n","\n","# Avaliação sem balanceamento\n","print(\"Avaliação Sem Balanceamento:\")\n","rf.fit(X_train, y_train)\n","y_pred = rf.predict(X_test)\n","print(classification_report(y_test, y_pred))\n","\n","# Avaliação com SMOTE (Over-sampling)\n","print(\"\\nAvaliação com SMOTE (Over-sampling):\")\n","X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n","rf.fit(X_train_smote, y_train_smote)\n","y_pred_smote = rf.predict(X_test)\n","print(classification_report(y_test, y_pred_smote))\n","\n","# Avaliação com Random Under-sampling\n","print(\"\\nAvaliação com Random Under-sampling:\")\n","X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)\n","rf.fit(X_train_rus, y_train_rus)\n","y_pred_rus = rf.predict(X_test)\n","print(classification_report(y_test, y_pred_rus))\n","\n","# Avaliação com Balanceamento por Custo\n","print(\"\\nAvaliação com Balanceamento por Custo:\")\n","rf_cost.fit(X_train, y_train)\n","y_pred_cost = rf_cost.predict(X_test)\n","print(classification_report(y_test, y_pred_cost))\n"]},{"cell_type":"code","source":["# Importar bibliotecas necessárias\n","import numpy as np\n","import pandas as pd\n","from sklearn.datasets import load_wine\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report\n","from imblearn.over_sampling import SMOTE\n","from imblearn.under_sampling import RandomUnderSampler\n","\n","# --------------------------------------\n","# INTRODUÇÃO SOBRE O DATASET WINE\n","# --------------------------------------\n","# O dataset 'Wine' do scikit-learn contém características químicas de vinhos.\n","# As classes representam três tipos diferentes de vinho:\n","# - Classe 0: Tipo de vinho 0 (cerca de 59% dos exemplos)\n","# - Classe 1: Tipo de vinho 1 (cerca de 39% dos exemplos)\n","# - Classe 2: Tipo de vinho 2 (cerca de 2% dos exemplos)\n","\n","# Vamos analisar o balanceamento do dataset.\n","\n","# --------------------------------------\n","# CARREGAMENTO DO DATASET\n","# --------------------------------------\n","\n","# Carregar o dataset Wine\n","data = load_wine()\n","\n","# Criar o DataFrame com as características (X) e a variável alvo (y)\n","X_wine = pd.DataFrame(data.data, columns=data.feature_names)\n","y_wine = pd.Series(data.target)\n","\n","# Exibir a distribuição das classes no dataset\n","print(\"Distribuição das classes antes do balanceamento:\")\n","print(y_wine.value_counts())  # Verificar o balanceamento das classes\n","\n","# --------------------------------------\n","# DIVISÃO EM TREINO E TESTE\n","# --------------------------------------\n","\n","# Divisão do dataset em treino (70%) e teste (30%)\n","X_train_wine, X_test_wine, y_train_wine, y_test_wine = train_test_split(X_wine, y_wine, test_size=0.8, random_state=42)\n","\n","# --------------------------------------\n","# TREINAMENTO SEM BALANCEAMENTO\n","# --------------------------------------\n","\n","# Criar o modelo de classificação (RandomForest)\n","print(\"Avaliação Sem Balanceamento:\")\n","rf_wine = RandomForestClassifier(random_state=42)\n","\n","# Ajustar o modelo ao conjunto de treino sem balanceamento\n","rf_wine.fit(X_train_wine, y_train_wine)\n","\n","# Fazer previsões no conjunto de teste\n","y_pred_wine = rf_wine.predict(X_test_wine)\n","\n","# Avaliar o desempenho do modelo\n","print(classification_report(y_test_wine, y_pred_wine))\n","\n","# --------------------------------------\n","# APLICANDO SMOTE (OVER-SAMPLING)\n","# --------------------------------------\n","\n","# Criar e aplicar o SMOTE no conjunto de treino\n","print(\"\\nAvaliação com SMOTE (Over-sampling):\")\n","smote_wine = SMOTE(random_state=42)\n","X_train_smote_wine, y_train_smote_wine = smote_wine.fit_resample(X_train_wine, y_train_wine)\n","\n","# Ajustar o modelo ao conjunto de treino balanceado (SMOTE)\n","rf_wine.fit(X_train_smote_wine, y_train_smote_wine)\n","\n","# Fazer previsões no conjunto de teste\n","y_pred_smote_wine = rf_wine.predict(X_test_wine)\n","\n","# Avaliar o desempenho do modelo com SMOTE\n","print(classification_report(y_test_wine, y_pred_smote_wine))\n","\n","# --------------------------------------\n","# APLICANDO RANDOM UNDER-SAMPLING\n","# --------------------------------------\n","\n","# Criar e aplicar o Random Under-sampling no conjunto de treino\n","print(\"\\nAvaliação com Random Under-sampling:\")\n","rus_wine = RandomUnderSampler(random_state=42)\n","X_train_rus_wine, y_train_rus_wine = rus_wine.fit_resample(X_train_wine, y_train_wine)\n","\n","# Ajustar o modelo ao conjunto de treino balanceado (Random Under-sampling)\n","rf_wine.fit(X_train_rus_wine, y_train_rus_wine)\n","\n","# Fazer previsões no conjunto de teste\n","y_pred_rus_wine = rf_wine.predict(X_test_wine)\n","\n","# Avaliar o desempenho do modelo com Random Under-sampling\n","print(classification_report(y_test_wine, y_pred_rus_wine))\n","\n","# --------------------------------------\n","# APLICANDO BALANCEAMENTO POR CUSTO\n","# --------------------------------------\n","\n","# Ajustar o modelo com balanceamento por custo (class_weight='balanced')\n","print(\"\\nAvaliação com Balanceamento por Custo:\")\n","rf_cost_wine = RandomForestClassifier(random_state=42, class_weight='balanced')\n","rf_cost_wine.fit(X_train_wine, y_train_wine)\n","\n","# Fazer previsões no conjunto de teste\n","y_pred_cost_wine = rf_cost_wine.predict(X_test_wine)\n","\n","# Avaliar o desempenho do modelo com balanceamento por custo\n","print(classification_report(y_test_wine, y_pred_cost_wine))\n","\n","# --------------------------------------\n","# EXERCÍCIO\n","# --------------------------------------\n","\n","# 1. Carregue e prepare o dataset Wine. Divida o dataset em treino e teste.\n","# 2. Aplique as técnicas de balanceamento (SMOTE, Random Under-sampling, balanceamento por custo) e compare os resultados usando as métricas de precisão, recall e F1-score.\n","\n","# 3. Faça uma análise crítica sobre qual técnica foi mais eficaz para balancear as classes e qual técnica teve o melhor desempenho.\n","\n","# 4. Responda às perguntas seguintes:\n","#    a) Qual técnica teve o melhor desempenho na classe minoritária?\n","#    b) Qual técnica resultou em melhor equilíbrio entre as classes?\n","#    c) Existe uma técnica que foi mais eficiente em termos de precisão?\n","\n","# 5. Modifique os parâmetros dos modelos ou tente outras técnicas para explorar mais os efeitos do balanceamento no modelo.\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EWBWZjI3n7p-","executionInfo":{"status":"ok","timestamp":1746752970338,"user_tz":180,"elapsed":1223,"user":{"displayName":"Leonardo Quirino","userId":"09188993055052121239"}},"outputId":"e4e72488-85e8-4202-9477-5aec486b723c"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Distribuição das classes antes do balanceamento:\n","1    71\n","0    59\n","2    48\n","Name: count, dtype: int64\n","Avaliação Sem Balanceamento:\n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.96      0.97        48\n","           1       0.96      0.91      0.94        57\n","           2       0.90      1.00      0.95        38\n","\n","    accuracy                           0.95       143\n","   macro avg       0.95      0.96      0.95       143\n","weighted avg       0.95      0.95      0.95       143\n","\n","\n","Avaliação com SMOTE (Over-sampling):\n","              precision    recall  f1-score   support\n","\n","           0       0.96      0.96      0.96        48\n","           1       0.96      0.88      0.92        57\n","           2       0.88      1.00      0.94        38\n","\n","    accuracy                           0.94       143\n","   macro avg       0.93      0.95      0.94       143\n","weighted avg       0.94      0.94      0.94       143\n","\n","\n","Avaliação com Random Under-sampling:\n","              precision    recall  f1-score   support\n","\n","           0       0.94      0.98      0.96        48\n","           1       0.98      0.84      0.91        57\n","           2       0.86      1.00      0.93        38\n","\n","    accuracy                           0.93       143\n","   macro avg       0.93      0.94      0.93       143\n","weighted avg       0.94      0.93      0.93       143\n","\n","\n","Avaliação com Balanceamento por Custo:\n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.96      0.97        48\n","           1       0.96      0.91      0.94        57\n","           2       0.90      1.00      0.95        38\n","\n","    accuracy                           0.95       143\n","   macro avg       0.95      0.96      0.95       143\n","weighted avg       0.95      0.95      0.95       143\n","\n"]}]},{"cell_type":"markdown","source":["# Data Leakage"],"metadata":{"id":"Lr24voTNReZx"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.datasets import make_classification\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Gerando um dataset artificial de classificação com classes desbalanceadas\n","X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_classes=2,\n","                           weights=[0.9, 0.1], random_state=42)\n","\n","# Convertendo os nomes das colunas para strings para evitar o erro\n","X = pd.DataFrame(X)\n","X.columns = X.columns.astype(str)  # Corrige os nomes das colunas para string\n","\n","# Data Leakage: Adicionando o rótulo como uma característica extra\n","X['target'] = y\n","\n","# Dividindo em treino e teste\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Garantindo que X_train e y_train estão corretamente formatados\n","print(f'Tamanho de X_train: {X_train.shape}')\n","\n","# Treinando o modelo com data leakage\n","model = RandomForestClassifier(random_state=42)\n","model.fit(X_train, y_train)  # Treinando o modelo\n","\n","# Fazendo previsões\n","y_pred = model.predict(X_test)\n","\n","# Avaliando o modelo\n","accuracy_with_leakage = accuracy_score(y_test, y_pred)\n","print(f'Acurácia com Data Leakage: {accuracy_with_leakage:.4f}')\n","\n","# Removendo a coluna 'target' para evitar Data Leakage\n","X_without_leakage = X.drop('target', axis=1)\n","\n","# Dividindo novamente em treino e teste sem Data Leakage\n","X_train, X_test, y_train, y_test = train_test_split(X_without_leakage, y, test_size=0.2, random_state=42)\n","\n","# Garantindo que X_train e y_train estão corretamente formatados\n","print(f'Tamanho de X_train sem leakage: {X_train.shape}')\n","\n","# Treinando o modelo novamente sem data leakage\n","model.fit(X_train, y_train)  # Treinando o modelo novamente\n","\n","# Fazendo previsões\n","y_pred = model.predict(X_test)\n","\n","# Avaliando o modelo sem Data Leakage\n","accuracy_without_leakage = accuracy_score(y_test, y_pred)\n","print(f'Acurácia sem Data Leakage: {accuracy_without_leakage:.4f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8n0LrKoSqA3s","executionInfo":{"status":"ok","timestamp":1746746059322,"user_tz":180,"elapsed":705,"user":{"displayName":"Leonardo Quirino","userId":"09188993055052121239"}},"outputId":"192df246-5df2-4532-9184-5900c3afe113"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Tamanho de X_train: (800, 21)\n","Acurácia com Data Leakage: 1.0000\n","Tamanho de X_train sem leakage: (800, 20)\n","Acurácia sem Data Leakage: 0.9500\n"]}]}]}